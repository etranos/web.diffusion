---
title: "diffusion, websites with 1 pc"
date: "`r format(Sys.time(), '%d %B, %Y, %H:%M')`"
output: 
  html_document:
    df_print: paged
    toc: true
    toc_float: true
knit: (function(inputFile, encoding) {
    rmarkdown::render(inputFile, encoding = encoding, output_dir = "../output")
  })
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(rprojroot)
# library(rgdal)
# library(rgeos)
library(sf)
library(spdep)
library(tmap)
#library(maptools)
library(knitr)
library(REAT)
library(tidygeocoder)
library(geosphere)
library(broom)
library(foreach)
library(raster)
library(plm)
library(lmtest)

options(scipen=10000)

# This is the project path
path <- find_rstudio_root_file()
```

## Load data

Postcode lookup.

[source](https://geoportal.statistics.gov.uk/datasets/postcode-to-output-area-to-lower-layer-super-output-area-to-middle-layer-super-output-area-to-local-authority-district-august-2021-lookup-in-the-uk/about)

```{r}
path.lookup <- paste0(path,"/data/raw/PCD_OA_LSOA_MSOA_LAD_AUG21_UK_LU.csv")
lookup <- read_csv(path.lookup) %>% 
  dplyr::select(pcds, oa11cd, lsoa11cd, msoa11cd, ladcd, ladnm) %>% 
  dplyr::rename(pc = pcds)
#glimpse(lookup)
# The problems refer to Welsh LAD names. Not a problem for the analysis.
#sapply(lookup, function(x) sum(is.na(x)))
# 10332 missing msoa11cd
```

The internet archive $1996$-$2010$ data is saved on /hdd.
The internet archive $2011$-$2012$ data is saved on ~/projects/web.diffusion/data/temp.

```{r}
n = 1 #number of unique postcodes. 
m = 12

data.folder <- "/hdd/internet_archive/archive/data/"
data.path9610 <- paste0(data.folder, "domain_pc_year.csv")
#Created by domain.R, which uses domain instead of host.
#This is what we use for the hyperlinks paper as per George's script

df9610 <- read_csv(data.path9610) 

data.path2011_2012 <- paste0(path, "/data/temp/domain_pc_year1112.csv")
#Created by domain1112.Rmd, which is based on domain.R and uses domain instead of host.
#This is what we use for the hyperlinks paper as per George's script

df1112 <- read_csv(data.path2011_2012)

df <- bind_rows(df9610, df1112) %>% 
  filter(
    #V1.domain < m,             # for multiple pc
    V1.domain == n,             # for n == 1
    year > 1995 & year <2013) %>%   
  left_join(lookup, by = "pc", suffix =c("","")) %>% 
  group_by(year, ladcd) %>%
  #summarise(n = n()) %>%            # for multiple pc  
  summarise(n = sum(V1.domain)) %>% # for n == 1 
  ungroup()

df <- df %>% filter(!is.na(ladcd)) %>% 
  complete(ladcd, year) %>% 
  replace(is.na(.), 0)

# tests for Scotland
# df %>% filter(substr(oa11cd, 1,1) =="S",
#               year==2010) %>% summarise(mean(n, na.rm = T))
# 
# df %>% filter(oa11cd=="S00090182")
# 
# test@data %>% filter(substr(id, 1,1) =="S",
#                      n!=0)
# 
# df %>% filter(substr(oa11cd, 1,1) =="W",
#               year==2003)
```

## Firms

```{r, eval=F}
firms <- read_csv("https://www.nomisweb.co.uk/api/v01/dataset/NM_142_1.data.csv?geography=1811939329...1811939332,1811939334...1811939336,1811939338...1811939428,1811939436...1811939442,1811939768,1811939769,1811939443...1811939497,1811939499...1811939501,1811939503,1811939505...1811939507,1811939509...1811939517,1811939519,1811939520,1811939524...1811939570,1811939575...1811939599,1811939601...1811939628,1811939630...1811939634,1811939636...1811939647,1811939649,1811939655...1811939664,1811939667...1811939680,1811939682,1811939683,1811939685,1811939687...1811939704,1811939707,1811939708,1811939710,1811939712...1811939717,1811939719,1811939720,1811939722...1811939730,1811939757...1811939767&date=latestMINUS10&industry=37748736&employment_sizeband=0&legal_status=0&measures=20100") %>% 
  dplyr::select(GEOGRAPHY_CODE, OBS_VALUE) %>% #GEOGRAPHY_NAME, 
  rename(ladcd = GEOGRAPHY_CODE,
         firms = OBS_VALUE)

df <- df %>% left_join(firms) %>% 
  mutate(n_by_firm = n/firms) %>% # N websites/firm
  #filter(!is.na(firms)) %>% 
  dplyr::select(-n, -firms) %>% 
  rename(n = n_by_firm)

# df %>% filter(is.na(n_by_firm))
# sapply(df %>% left_join(firms), function(x) sum(is.na(x)))
```

## spatial data

```{r}
# get LA for the UK
path.geo <- paste0(path, "/data/raw/Local_Authority_Districts_(December_2021)_UK_BUC.geojson")
la <- readOGR(path.geo)
# source: https://geoportal.statistics.gov.uk/

# spatial transformations
la <- spTransform(la, CRS("+init=epsg:4326"))

la.f <- fortify(la, region = "LAD21CD")

# cities
cities <- maps::world.cities %>% 
  filter(country.etc=="UK") %>% 
  arrange(pop) %>% tail(10) 
cities.sf <- st_as_sf(cities, coords = c("long", "lat"), crs = 4326)
```

## lisa maps

```{r}

path.out <- paste0(path, "/outputs/lisa/lisa_level_pc", n, "_la") # for unique PC
#path.out <- paste0(path, "/outputs/lisa/lisa_level_pc", m, "_la")  # for multiple PC

morani <- data.frame()

#spatial weight matrix
sf_use_s2(FALSE)
nb <- poly2nb(la)
listw <- nb2listw(nb, style = "W", zero.policy = T)

for (t in 1996:2012){
test <- la
test@data <- test@data %>% left_join(df[df$year==t,], by = c("LAD21CD"="ladcd")) %>% 
  mutate(n = ifelse(is.na(n), 0, n),           # 0 for NAs and the same for year
         year = ifelse(is.na(year), t, year))
  
#spatial weight matrix
#moved out of the loop

#Moran's I
globalMoran <- moran.test(test$n, listw, zero.policy = T, na.action = na.exclude)
a <- cbind(globalMoran$estimate[[1]],globalMoran$p.value, t[1])
morani <- rbind(a, morani)

#LISA
lmoran<- cbind(test@data, localmoran(test$n, listw,  adjust.x=TRUE, zero.policy = T, na.action = na.exclude))
#lmoran

# centers the local Moran's around the mean
lmoran$Ii <- lmoran$Ii - mean(lmoran$Ii, na.rm = TRUE) 
lmoran$lag.n<-  lag.listw(listw,lmoran$n, NAOK = TRUE)

# centers the variable of interest around its mean

lmoran$ns <- lmoran$n - mean(lmoran$n, na.rm = TRUE) 
lmoran$lag.n <- lmoran$lag.n - mean(lmoran$lag.n, na.rm = TRUE) 

signif <- 0.05
#lmoran

lmoran <- lmoran%>% 
  mutate(quadrant= ifelse(ns>0 & lag.n > 0, 1, 0)) %>% 
  mutate(quadrant= ifelse(ns<0 & lag.n < 0, 2, quadrant)) %>% 
  mutate(quadrant= ifelse(ns<0 & lag.n > 0, 3, quadrant)) %>% 
  mutate(quadrant= ifelse(ns>0 & lag.n < 0, 4, quadrant)) %>%   
  #mutate(quadrant= ifelse(lmoran$`Pr(z > 0)` > signif, 0, quadrant)) #%>% 
  mutate(quadrant= ifelse(lmoran$`Pr(z != E(Ii))` > signif, 0, quadrant)) #%>% 


#   mutate(quadrant2= ifelse(ANC_st>0 & lagANC_st > 0, 1, 0)) %>% 
# mutate(quadrant2= ifelse(ANC_st<0 & lagANC_st < 0, 2, quadrant2)) %>% 
#   mutate(quadrant2= ifelse(ANC_st<0 & lagANC_st > 0, 3, quadrant2)) %>% 
#  mutate(quadrant2= ifelse(ANC_st>0 & lagANC_st < 0, 4, quadrant2)) %>% 
#  mutate(quadrant2= ifelse(lmoran$LISA_PANC > signif, 0, quadrant2))
  
mun_merge_new<- merge(test, lmoran, by="LAD21CD")

# R p value map
breaks = c(0, 1, 2, 3, 4, 5) 

cities <- maps::world.cities %>% 
  filter(country.etc=="UK") %>% 
  arrange(pop) %>% tail(10) 
cities.sf <- st_as_sf(cities, coords = c("long", "lat"), crs = 4326)


map <- tm_shape(mun_merge_new) + tm_fill(col = "quadrant", breaks = breaks, 
                                         palette = c("white","red","blue",
                                                     rgb(0,0,1,alpha=0.4),
                                                     rgb(1,0,0,alpha=0.4)), 
                                         labels = c("Not significant",
                                                    "High-High",
                                                    "Low-Low",
                                                    "Low-High",
                                                    "High-Low"), 
                                         title="LISA, websites per firm in a LA") +
  tm_legend(text.size = 1) +
  #tm_scale_bar(position = c("LEFT", "BOTTOM"),text.size = 1.0)+
  #tm_compass(type = "8star",   position = c("RIGHT", "BOTTOM"),      show.labels = 2,   text.size = 0.5)+
  #tm_borders(alpha=.1) +
  tm_borders(lwd = 0) +
  tm_shape(la, simplify = .2) + tm_borders(alpha=1, lwd = .7) +
  tm_shape(cities.sf) + tm_dots() + tm_text("name", size = .5) +
  tm_layout( frame = FALSE,  title = t) #"LISA with the R p-values ")
tmap_save(map, filename = paste(path.out, t, ".png", sep = ""))
}

#ggplot map solution.
# mun_merge_new %>% st_as_sf(crs = 27700) %>% #st_transform(4326) %>%
#   ggplot()+
#   geom_sf(aes(fill = as.factor(quadrant)))
# ggsave("test_ggplot.png", path = path)

```

## lisa maps parallel

```{r, eval=F}

path.out <- paste0(path, "/outputs/lisa/lisa_level_pc_test", n, "_la") # for unique PC
#path.out <- paste0(path, "/outputs/lisa/lisa_level_pc", m, "_la")  # for multiple PC

#setup cluster
#https://www.blasbenito.com/post/02_parallelizing_loops_with_r/
n.cores <- parallel::detectCores() - 1
my.cluster <- parallel::makeCluster(
  n.cores, 
  type = "PSOCK"
  )
print(my.cluster)
doParallel::registerDoParallel(cl = my.cluster)
foreach::getDoParWorkers()

morani <- data.frame()

#spatial weight matrix
sf_use_s2(FALSE)
nb <- poly2nb(la)
listw <- nb2listw(nb, style = "W", zero.policy = T)

#for (t in 1996:2012){
foreach(t = 1996:2012, .packages = c("tidyverse",
                                     "rgdal",
                                     "rgeos",
                                     "spdep",
                                     "tmap",
                                     "maptools",
                                     "knitr",
                                     "broom")) %dopar% {
test <- la
test@data <- test@data %>% left_join(df[df$year==t,], by = c("LAD21CD"="ladcd")) %>% 
  mutate(n = ifelse(is.na(n), 0, n),           # 0 for NAs and the same for year
         year = ifelse(is.na(year), t, year))
  
#spatial weight matrix
#moved out of the loop

#Moran's I
globalMoran <- moran.test(test$n, listw, zero.policy = T, na.action = na.exclude)
a <- cbind(globalMoran$estimate[[1]],globalMoran$p.value, t[1])
morani <- rbind(a, morani)

#LISA
lmoran<- cbind(test@data, localmoran(test$n, listw,  adjust.x=TRUE, zero.policy = T, na.action = na.exclude))
#lmoran

# centers the local Moran's around the mean
lmoran$Ii <- lmoran$Ii - mean(lmoran$Ii, na.rm = TRUE) 
lmoran$lag.n<-  lag.listw(listw,lmoran$n, NAOK = TRUE)

# centers the variable of interest around its mean

lmoran$ns <- lmoran$n - mean(lmoran$n, na.rm = TRUE) 
lmoran$lag.n <- lmoran$lag.n - mean(lmoran$lag.n, na.rm = TRUE) 

signif <- 0.05
#lmoran

lmoran <- lmoran%>% 
  mutate(quadrant= ifelse(ns>0 & lag.n > 0, 1, 0)) %>% 
  mutate(quadrant= ifelse(ns<0 & lag.n < 0, 2, quadrant)) %>% 
  mutate(quadrant= ifelse(ns<0 & lag.n > 0, 3, quadrant)) %>% 
  mutate(quadrant= ifelse(ns>0 & lag.n < 0, 4, quadrant)) %>%   
  #mutate(quadrant= ifelse(lmoran$`Pr(z > 0)` > signif, 0, quadrant)) #%>% 
  mutate(quadrant= ifelse(lmoran$`Pr(z != E(Ii))` > signif, 0, quadrant)) #%>% 


#   mutate(quadrant2= ifelse(ANC_st>0 & lagANC_st > 0, 1, 0)) %>% 
# mutate(quadrant2= ifelse(ANC_st<0 & lagANC_st < 0, 2, quadrant2)) %>% 
#   mutate(quadrant2= ifelse(ANC_st<0 & lagANC_st > 0, 3, quadrant2)) %>% 
#  mutate(quadrant2= ifelse(ANC_st>0 & lagANC_st < 0, 4, quadrant2)) %>% 
#  mutate(quadrant2= ifelse(lmoran$LISA_PANC > signif, 0, quadrant2))
  
mun_merge_new<- merge(test, lmoran, by="LAD21CD")

# R p value map
breaks = c(0, 1, 2, 3, 4, 5) 

cities <- maps::world.cities %>% 
  filter(country.etc=="UK") %>% 
  arrange(pop) %>% tail(10) 
cities.sf <- st_as_sf(cities, coords = c("long", "lat"), crs = 4326)


map <- tm_shape(mun_merge_new, projection = "+init=epsg:4326") + tm_fill(col = "quadrant", breaks = breaks, 
                                         palette = c("white","red","blue",
                                                     rgb(0,0,1,alpha=0.4),
                                                     rgb(1,0,0,alpha=0.4)), 
                                         labels = c("Not significant",
                                                    "High-High",
                                                    "Low-Low",
                                                    "Low-High",
                                                    "High-Low"), 
                                         title="LISA, websites per firm in a LA") +
  tm_legend(text.size = 1) +
  #tm_scale_bar(position = c("LEFT", "BOTTOM"),text.size = 1.0)+
  #tm_compass(type = "8star",   position = c("RIGHT", "BOTTOM"),      show.labels = 2,   text.size = 0.5)+
  #tm_borders(alpha=.1) +
  tm_borders(lwd = 0) +
  tm_shape(la, simplify = .2) + tm_borders(alpha=1, lwd = .7) +
  tm_shape(cities.sf) + tm_dots() + tm_text("name", size = .5) +
  tm_layout( frame = FALSE,  title = t) #"LISA with the R p-values ") +
tmap_options(check.and.fix = TRUE)
tmap_save(map, filename = paste(path.out, t, ".png", sep = ""))
                                     }

```

## Moran I

```{r}
path.out <- paste0(path, "/outputs/lisa/morani_la.csv")
morani %>% as_tibble() %>% 
  rename('morani'=V1,
                   p = V2,
                   year = V3) %>% 
  #kable() %>% 
  write_csv(path.out)
```

## Gini

```{r}

# No need to add 0s like OAs as there aren't any LA with 0s

gini.df <- data.frame()

for (t in 1996:2012){
    a <- df %>% filter(year==t)
  b <- as.data.frame(gini(a$n))
  b$year = t
  gini.df <- rbind(gini.df, b)
}

path.out <- paste0(path, "/outputs/gini_la.csv")
gini.df %>% write_csv(path.out)
```

## Getis-Ord

```{r eval = F}

t= 1998
local_g <- localG(OA.Census$Qualification, nb_lw)
local_g <- localG(df[df$year==t,]$n, listw)

local_g <- cbind(OA.Census, as.matrix(local_g))
names(local_g)[6] <- "gstat"

```

## Distances to cities and retail centres

First set up the destinations. Origins are all the LA.

Major cities from [source](https://www.citypopulation.de/en/uk/cities/).
Retail centres from [source](https://data.cdrc.ac.uk/dataset/retail-centre-boundaries)

```{r}
# LA centroids
la.c <- gCentroid(la, byid=TRUE)@coords %>% 
  as.data.frame() %>%
  bind_cols(la@data) %>% 
  dplyr::select(LAD21CD, x, y) %>% 
  remove_rownames()

# cities
city.names <- c("London, UK", 
"Birmingham, UK",
"Glasgow, UK",
"Liverpool, UK",
"Bristol, UK",
"Manchester, UK",
"Sheffield, UK",
"Leeds, UK",
"Edinburgh, UK",
"Leicester, UK")	

cities <- geo(city.names, no_query = F, method = "arcgis")

# retail centres
geo.path <- paste0(path, "/data/raw/Retail_Boundaries_UK.gpkg")
retail <-readOGR(geo.path) 
#retail.major.cetres <- subset(retail, retail$Classification == "Major Town Centre") #%>% 
retail.major.cetres.help <- gCentroid(retail, byid=TRUE)@coords %>% 
  as.data.frame() %>% 
  add_rownames(var = "id") #%>%

retail.major.cetres <- retail.major.cetres.help %>% 
  st_as_sf(coords = c("x", "y"), crs = 27700) %>%
  st_transform(4326) %>%
  st_coordinates() %>%
  as_tibble() %>% 
  bind_cols(retail.major.cetres.help$id) %>% 
  rename(id = '...3') %>% 
  left_join(retail@data %>% mutate(id = rownames(retail@data)), by = 'id')
```

Distance to cities

```{r}
dist <- distm(cbind(la.c$x, la.c$y), cbind(cities$long, cities$lat), fun=distHaversine) 
dist <- round((dist/1000),2) %>% 
  as_tibble()  

city.names <- city.names %>% stringr::str_remove(", UK")
names(dist) <- city.names 

dist <- dist %>% bind_cols(la.c$LAD21CD) %>% 
  rename(ladcd = last_col()) %>% 
  relocate(ladcd)

# dist$dist <- names(dist)[apply(dist[-1], MARGIN = 1, FUN = which.min)]
# dist$distMet <- apply(dist[,2:11], 1, min)

dist <- transform(dist, dist = do.call(pmin, dist[-1]))



# NOT USED AS IT SCREWS UP THE REGRESSIONS
# Complete panel, N = 3871903, 17 year * 227759 OA
# df <- df %>% bind_rows(dist %>% select(oa11cd)) %>% 
#   mutate(year = ifelse(is.na(year),1000, year),
#          country = substring(oa11cd, 1, 1)) %>% 
#   filter(country != "L" & country != "M" & country != "N") %>% 
#   filter(!is.na(country)) %>% 
#   complete(year, oa11cd, fill = list(n = 0)) %>% 
#   filter(year!=1000,
#          !is.na(oa11cd)) %>% 
#   select(-country)



# tests
# test$country <- substring(test$oa11cd, 1, 1)
# unique(test$country)
# length(unique(test$oa11cd))

# calculate area
la$SHAPE_Area <- area(la) #/ 1000000

# Join with distance and area
df <- df %>% left_join(dist, by = c("ladcd" = "ladcd")) %>% 
  left_join(la@data, by = c("ladcd" = "LAD21CD")) %>% 
  rename(area = SHAPE_Area) %>% 
  relocate(area, .after = n) %>% 
  mutate(area = area / 1000000,
         density = n / area) %>% 
  relocate(density, .after = area)
sapply(df, function(x) sum(is.na(x)))
```

Distance to retail centres

```{r}
dist.retail <- distm(cbind(la.c$x, la.c$y), cbind(retail.major.cetres$X, retail.major.cetres$Y), fun=distHaversine) 
dist.retail <- round((dist.retail/1000),2) %>% 
  as_tibble()  

# retail.names <- retail.major.cetres$RC_Name
# names(dist.retail) <- retail.names 

dist.retail <- dist.retail %>% bind_cols(la.c$LAD21CD) %>% 
  rename(LAD21CD = last_col()) %>% 
  relocate(LAD21CD)

# Minimum distance 
dist.retail <- transform(dist.retail, dist.retail = do.call(pmin, dist.retail[-1]))
dist.retail <- dist.retail %>% dplyr::select(LAD21CD, dist.retail)

# Join with complete panel
df <- df %>% left_join(dist.retail, by = c("ladcd" = "LAD21CD")) 

sapply(df, function(x) sum(is.na(x)))
```

## Panel regressions

```{r}
# London
model <- plm(log(n+0.001) ~ log(London+.001)*as.factor(year), 
             data = df,
             index = c("ladcd", "year"),
             model = "within",
             effect = "twoways")
summary(model)

est <- coeftest(model, vcov = vcovHC, type = "HC1") # same
int <- confint(est)

out.model <- bind_cols(tidy(est), 
                       as_tibble(int)) %>% 
  mutate_if(is.numeric, round, 2) %>% 
  mutate(year = 1997:2012) %>% 
  rename(conf.low = '2.5 %',
         conf.high = '97.5 %')

path.out <- paste0(path,"/outputs/lisa/b_panel_dist_london_la.png")
ggplot(out.model, aes(x=reorder(year, year), y=estimate)) +
  geom_errorbar(aes(ymin=conf.low, ymax=conf.high), 
                    width = 0.2,size  = 1,
                    position = "dodge", color="turquoise4") +
  #geom_hline(yintercept = 0, color = "red", size = 1) +
  geom_point() + coord_flip() +
  ylab("Interaction coefficients: distance*year, robust st. errors") + xlab("") + 
  ggtitle("Regression coefficients: distance to London on website counts, LA") +
  theme(plot.title = element_text(hjust = 0.5))
ggsave(path.out)

# Cities
model <- plm(log(n+0.001) ~ log(dist+.001)*as.factor(year), 
             data = df,
             index = c("ladcd", "year"),
             model = "within",
             effect = "twoways")
summary(model)

est <- coeftest(model, vcov = vcovHC, type = "HC1") # same
int <- confint(est)

out.model <- bind_cols(tidy(est), 
                       as_tibble(int)) %>% 
  mutate_if(is.numeric, round, 2) %>% 
  mutate(year = 1997:2012) %>% 
  rename(conf.low = '2.5 %',
         conf.high = '97.5 %')

path.out <- paste0(path,"/outputs/lisa/b_panel_dist_cities_la.png")
ggplot(out.model, aes(x=reorder(year, year), y=estimate)) +
  geom_errorbar(aes(ymin=conf.low, ymax=conf.high), 
                    width = 0.2,size  = 1,
                    position = "dodge", color="turquoise4") +
  #geom_hline(yintercept = 0, color = "red", size = 1) +
  geom_point() + coord_flip() +
  ylab("Interaction coefficients: distance*year, robust st. errors") + xlab("") + 
  ggtitle("Regression coefficients: distance to Cities on website counts, LA") +
  theme(plot.title = element_text(hjust = 0.5))
ggsave(path.out)

# Retail centres
model <- plm(log(n+0.001) ~ log(dist.retail+.001)*as.factor(year), 
             data = df,
             index = c("ladcd", "year"),
             model = "within",
             effect = "twoways")
summary(model)

est <- coeftest(model, vcov = vcovHC, type = "HC1") # same
int <- confint(est)

out.model <- bind_cols(tidy(est), 
                       as_tibble(int)) %>% 
  mutate_if(is.numeric, round, 2) %>% 
  mutate(year = 1997:2012) %>% 
  rename(conf.low = '2.5 %',
         conf.high = '97.5 %')

path.out <- paste0(path,"/outputs/lisa/b_panel_dist_retail_la.png")
ggplot(out.model, aes(x=reorder(year, year), y=estimate)) +
  geom_errorbar(aes(ymin=conf.low, ymax=conf.high), 
                    width = 0.2,size  = 1,
                    position = "dodge", color="turquoise4") +
  #geom_hline(yintercept = 0, color = "red", size = 1) +
  geom_point() + coord_flip() +
  ylab("Interaction coefficients: distance*year, robust st. errors") + xlab("") + 
  ggtitle("Regression coefficients: distance to Retail Centres on website counts, LA") +
  theme(plot.title = element_text(hjust = 0.5))
ggsave(path.out)
```

## Website density regressions to London

```{r}
dens.London <- data.frame()
out.model <- data.frame()

for (t in 1996:2012){
  model <- lm(log(n+0.001) ~ log(London), data = df[df$year==t,]) #density
  r2 <- as.data.frame(summary(model)$r.squared)
  r2$year = t
  dens.London <- rbind(r2, dens.London)
  
  out.model_ <- tidy(model, conf.int = TRUE) %>% 
    slice(2) %>% 
    mutate_if(is.numeric, round, 2)
  out.model <- rbind(out.model_, out.model)
}

names(dens.London)[1] <- "rsquared"

path.out <- paste0(path,"/outputs/rsq_dist_london_la.png")
ggplot(dens.London) +
  geom_line(aes(x=year, y = rsquared)) +
  ylab("Rsquared") + 
  ggtitle("Regression fit, distance to London on website density, LA") +
  theme(plot.title = element_text(hjust = 0.5))
ggsave(path.out)

out.model <- out.model %>% 
  mutate(year = 1996:2012)

path.out <- paste0(path,"/outputs/b_dist_london_la.png")
ggplot(out.model, aes(x=reorder(year, year), y=estimate)) +
#ggplot(out.model, aes(x=year, y = estimate)) +  
           geom_errorbar(aes(ymin=conf.low, ymax=conf.high), 
                       width = 0.2,size  = 1,
                       position = "dodge", color="turquoise4") +
  #geom_hline(yintercept = 0, color = "red", size = 1) +
  geom_point() + coord_flip() +
  ylab("distance coefficient") + xlab("") + 
  ggtitle("Regression coefficients, distance to London on website density, LA") +
  theme(plot.title = element_text(hjust = 0.5)) 
ggsave(path.out)
```

## Website density regressions to the nearest city

```{r}
dens.distMet <- data.frame()
out.modelMet <- data.frame()

for (t in 1996:2012){
  model <- lm(log(density+0.001) ~ log(dist), data = df[df$year==t,])
  r2 <- as.data.frame(summary(model)$r.squared)
  r2$year = t
  dens.distMet <- rbind(r2, dens.distMet)
  
  out.model_ <- tidy(model, conf.int = TRUE) %>% 
    slice(2) %>% 
    mutate_if(is.numeric, round, 2)
  out.modelMet <- rbind(out.model_, out.modelMet)
}

names(dens.distMet)[1] <- "rsquared"

path.out <- paste0(path,"/outputs/rsq_dist_city_la.png")
ggplot(dens.distMet) +
  geom_line(aes(x=year, y = rsquared)) +
  ylab("Rsquared") + 
  ggtitle("Regression fit, distance to nearest city on website density, LA") +
  theme(plot.title = element_text(hjust = 0.5)) 
ggsave(path.out)

out.modelMet <- out.modelMet %>% 
  mutate(year = 1996:2012)

path.out <- paste0(path,"/outputs/b_dist_city_la.png")
ggplot(out.modelMet, aes(x=reorder(year, year), y=estimate)) +
           geom_errorbar(aes(ymin=conf.low, ymax=conf.high), 
                       width = 0.2,size  = 1,
                       position = "dodge", color="turquoise4") +
  #geom_hline(yintercept = 0, color = "red", size = 1) +
  geom_point() + coord_flip() +
  ylab("distance coefficient") + xlab("") + 
  ggtitle("Regression coefficients, distance to nearest city on website density, LA") +
  theme(plot.title = element_text(hjust = 0.5)) 
ggsave(path.out)
```

## Website density regressions to the nearest retail centre

```{r}
dens.dist.retail <- data.frame()
out.model.retail <- data.frame()

for (t in 1996:2012){
  model <- lm(log(n+0.001) ~ log(dist.retail+0.001), data = df[df$year==t,]) #density
  r2 <- as.data.frame(summary(model)$r.squared)
  r2$year = t
  dens.dist.retail <- rbind(r2, dens.dist.retail)
  
  out.model_ <- tidy(model, conf.int = TRUE) %>% 
    slice(2) %>% 
    mutate_if(is.numeric, round, 2)
  out.model.retail <- rbind(out.model_, out.model.retail)
}

names(dens.dist.retail)[1] <- "rsquared"

path.out <- paste0(path,"/outputs/rsq_dist_centre_la.png")
ggplot(dens.dist.retail) +
  geom_line(aes(x=year, y = rsquared)) +
  ylab("Rsquared") + 
  ggtitle("Regression fit, distance to nearest retail centre on website density, LA") +
  theme(plot.title = element_text(hjust = 0.5)) 
ggsave(path.out)

out.model.retail <- out.model.retail %>% 
  mutate(year = 1996:2012)

path.out <- paste0(path,"/outputs/b_dist_centre_la.png")
ggplot(out.model.retail, aes(x=reorder(year, year), y=estimate)) +
           geom_errorbar(aes(ymin=conf.low, ymax=conf.high), 
                       width = 0.2,size  = 1,
                       position = "dodge", color="turquoise4") +
  #geom_hline(yintercept = 0, color = "red", size = 1) +
  geom_point() + coord_flip() +
  ylab("distance coefficient") + xlab("") + 
  ggtitle("Regression coefficients, distance to nearest retail centre on website density, LA") +
  theme(plot.title = element_text(hjust = 0.5)) 
ggsave(path.out)


# library(pscl)
# m1 <- zeroinfl((n) ~ log(dist.retail+0.001),
#   data = df[df$year==t,], dist = "negbin", EM = TRUE)
# summary(m1)
# 
# df %>% filter(year == 1996) %>% 
#   group_by(group = cut(n, breaks = c(0, 1, 2, 10, 100, 1000, 10000), include.lowest = T, right = F)) %>%  #seq(0, max(n), 100))) %>%
#   summarise(n = sum(n))
```

All R^2 dataframe

```{r}
path.out <- paste0(path, "/outputs/r2_all_la.csv")

r2.all <- dens.London %>% 
  rename(London.LA = rsquared) %>% 
  left_join(dens.distMet) %>% 
  rename(cities.LA = rsquared) %>% 
  left_join(dens.dist.retail) %>% 
  rename(retail.LA = rsquared) %>% 
  relocate(year, .before = London.LA) %>% 
  arrange(year)

write_csv(r2.all, path.out)
```

## Spatial panel

```{r}
#spatial weight matrix
sf_use_s2(FALSE)
nb <- poly2nb(la, queen = T, snap = 1)
listw <- nb2listw(nb, style = "W", zero.policy = T)

test <- la
test@data <- test@data %>% left_join(df[df$year==t,], by = c("LAD21CD"="ladcd")) %>% 
  mutate(n = ifelse(is.na(n), 0, n),           # 0 for NAs and the same for year
         year = ifelse(is.na(year), t, year))

# Load required libraries
library(spdep)
library(splm)

# Assuming you have a dataset named 'data' containing your variables: Y, W, Wc, and X

# Create spatial lag matrices
W <- mat2listw(W, style="W")
Wc <- mat2listw(Wc, style="W")

# Estimate spatial panel model
spatial_panel_model <- spml(n ~ density + London + dist + dist.retail, 
                            listw=listw,
                            data=df %>% filter(!is.na(n)), 
                            index = c("ladcd", "year"),
                            effect = "individual",
                            #method = "BFGS", # eigen
                            model= "random", 
                            lag=TRUE, 
                            na.action = na.omit) #na.fail, 
                            #zero.policy = NULL)

m.spreml <- spreml(n ~ density + London + dist + dist.retail, 
                            w=listw,
                            data=df %>% filter(!is.na(n)), 
                            index = c("ladcd", "year"),
                            effect = "individual",
                            #method = "BFGS", # eigen
                            lag=TRUE, 
                            na.action = na.omit) #na.fail, 
                            #zero.policy = NULL)


# Print summary of the model
summary(m.spreml)
```

calculate k neighbours and find out why can't have spatial FE. Hierarchical?

```{r}
#install.packages('SDPDmod')
library(SDPDmod)

#spatial weights matrix
sf_use_s2(FALSE)
nb <- poly2nb(la, queen = T, snap = 1)
listw <- nb2listw(nb, style = "W", zero.policy = T)

#spatial weight matrix
binary_matrix <- nb2mat(nb, style = "B", zero.policy = TRUE)
class(binary_matrix)
w.binary <- rownor(binary_matrix)
isrownor(w.binary)
w.binary <- rownor(binary_matrix)
isrownor(w.binary)

#spatial weights matrix
library("sf")
path.geo <- paste0(path, "/data/raw/Local_Authority_Districts_(December_2021)_UK_BUC.geojson")
la.sf <- st_read(path.geo)
W_2n <- mOrdNbr(sf_pol = la.sf, m = 2) ## second order neighbors
W_knn <- mNearestN(distMat = gN3dist, m = 5) ## 5 nearest neighbors

#spatial weights matrix
sf_use_s2(FALSE)
la.c <- st_centroid(la.sf)
kn <- knearneigh(la.c, k = 5)
knn <- knn2nb(kn, row.names = NULL, sym = FALSE)
knn_binary_matrix <- nb2mat(knn, style = "W", zero.policy = TRUE)
isrownor(knn_binary_matrix)

mod2<-SDPDm(formula = n ~ density,# + London,# + dist + dist.retail, 
            #W = w.binary,
            #W = binary_matrix,
            #W = knn_binary_matrix,
            W = knn_binary_matrix,
            data=df %>% drop_na(),
            index = c("ladcd", "year"),
            model = "sar", 
            effect = "twoways",
            dynamic = T,
            LYtrans = TRUE, #it affects coefficients, need to read about it
            tlaginfo = list(ind = NULL, tl = T, stl = T),
            )
summary(mod2)

# if distances are included, effect = year. 
# Rho is positive and sig, AR is positive and sig, BUT Wn(t-1) is negative and sig
```
